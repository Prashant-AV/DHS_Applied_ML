{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea9cf96-6d83-4078-9db7-abba3317c3dd",
   "metadata": {},
   "source": [
    "# Gemini\n",
    "The Gemini API gives you access to the latest generative AI models from Google.\n",
    "\n",
    "#### Prerequisites  \n",
    "Python 3.9+  \r\n",
    "An installation of jupyter to run the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f3c7a5-0402-44bf-af8b-9f2ae1cd1951",
   "metadata": {},
   "source": [
    "#### For Better Display of Formatted Text and Code in Jupyter Notebooks\n",
    "\n",
    "The to_markdown function is used to convert a given text into Markdown format, ensuring a clear and structured display of both regular text and code blocks within Jupyter notebooks. It enhances readability by replacing bullet points and correctly formatting code, making it ideal for presenting mixed content in an organized manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185ccd2a-1fbf-4242-b2f5-63ddb9d1bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "    def format_lines(lines):\n",
    "        formatted_lines = []\n",
    "        in_code_block = False\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith('```'):\n",
    "                in_code_block = not in_code_block\n",
    "                formatted_lines.append(line)\n",
    "            elif in_code_block:\n",
    "                formatted_lines.append(line)\n",
    "            else:\n",
    "                if line.startswith('•'):\n",
    "                    line = '  *' + line[1:]\n",
    "                formatted_lines.append('> ' + line)\n",
    "        return formatted_lines\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    formatted_lines = format_lines(lines)\n",
    "    return Markdown('\\n'.join(formatted_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb49ed-d9a8-4a30-90ab-4b692761ec4f",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The Python SDK for the Gemini API, is contained in the google-generativeai package. Install the dependency using pip :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baac11be-3dd3-4090-8152-0e154f9edab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b5c1a-8c3f-4980-a3b1-02011d911a5b",
   "metadata": {},
   "source": [
    "### API KEY \n",
    "\n",
    "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.  \r\n",
    "[Get an Api Key](https://aistudio.google.com/app/apikey)\n",
    "ey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913d74f2-8b41-43a1-8ba7-f8566a59920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfe4c30-e859-4c30-a26b-b53b12f73df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\rjakh\\anaconda3\\envs\\pyenv3117\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Install python-dotenv if not already installed\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280c73a-5756-4c2e-961e-1225de204cf5",
   "metadata": {},
   "source": [
    "#### Create a file named .env in your project directory. This file will store your API key.\n",
    "\n",
    "**Example** : GOOGLE_API_KEY=Put_the_key_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbd3c02-c342-4c90-929f-4d23b0f537e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"d:/k2analytics/datafile/Google_Gemini_API_Key.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract value for a specific key\n",
    "GOOGLE_API_KEY = data['GOOGLE_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a64429f-b42b-4f5a-b465-c5afacb34444",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key = GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127c942-d1bf-41f3-b4e7-8e31cc20470b",
   "metadata": {},
   "source": [
    "## Models \n",
    "\n",
    "The Gemini API offers different models that are optimized for specific use cases. Here's a brief overview of Gemini variants that are available:\n",
    "\n",
    "[Models](https://ai.google.dev/gemini-api/docs/models/gemini?authuser=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b70c4f-96c9-43b5-ae56-f6a15b9c3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e18650-e185-409b-880a-793f538cf87c",
   "metadata": {},
   "source": [
    "The **generate_content method** can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. The available models only support text and images as input, and text as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d1c4a5-7a18-407b-bce7-3d2ae63e20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is Prompt Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27570907-84ac-4874-814a-307f5c27a304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ## Prompt Engineering: Crafting Instructions for Intelligent Machines\n",
       "> \n",
       "> Prompt engineering is the art and science of crafting effective prompts to elicit desired responses from artificial intelligence (AI) systems, particularly large language models (LLMs) like ChatGPT. It's like giving clear and specific instructions to a highly skilled but literal-minded assistant.\n",
       "> \n",
       "> **Think of it this way:**\n",
       "> \n",
       "> * **AI:** The powerful but directionless engine.\n",
       "> * **Prompt:** The steering wheel and instructions that guide the engine.\n",
       "> * **Output:** The destination reached, shaped by the prompt's quality.\n",
       "> \n",
       "> **Why is Prompt Engineering Important?**\n",
       "> \n",
       "> LLMs are trained on massive datasets, making them capable of impressive feats.  However, they need guidance to understand your specific needs and deliver relevant results. This is where prompt engineering comes in. \n",
       "> \n",
       "> A well-crafted prompt can:\n",
       "> \n",
       "> * **Improve accuracy and relevance:** Get more precise and tailored outputs.\n",
       "> * **Unlock hidden capabilities:** Explore creative uses of the AI beyond basic tasks.\n",
       "> * **Control output format:** Generate text, code, lists, and more in your desired style.\n",
       "> * **Enhance consistency:** Ensure predictable results across similar prompts.\n",
       "> \n",
       "> **Key Elements of Prompt Engineering:**\n",
       "> \n",
       "> * **Clear Intent:** Define your objective clearly. What do you want the AI to achieve?\n",
       "> * **Context & Background:** Provide relevant information and examples to guide the AI.\n",
       "> * **Constraints & Formatting:** Specify desired length, style, format, and tone.\n",
       "> * **Keywords & Phrases:** Use relevant terms that the AI understands.\n",
       "> * **Iterative Refinement:** Experiment, analyze results, and tweak prompts for improvement.\n",
       "> \n",
       "> **Examples of Prompt Engineering in Action:**\n",
       "> \n",
       "> * **Basic:** \"Write a short story about a cat who goes on an adventure.\"\n",
       "> * **Advanced:**  \"Write a humorous short story, in the style of Douglas Adams, about a cat named Mittens who travels through time in a malfunctioning washing machine. Limit the story to 500 words.\"\n",
       "> \n",
       "> **The Future of Prompt Engineering:**\n",
       "> \n",
       "> Prompt engineering is rapidly evolving as AI technology advances. New techniques and tools are emerging, making it easier for users to interact with AI effectively. \n",
       "> \n",
       "> **In a nutshell, prompt engineering is the key to unlocking the full potential of AI and transforming how we interact with machines.** \n",
       "> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7747d35-9398-4326-a4fd-7c0f1ebbbd91",
   "metadata": {},
   "source": [
    "## Prompt Engineering for Linear Models \n",
    "\n",
    "Linear Models: Often used in tasks like regression .  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65571fd3-7338-4533-b933-ce5e658be8de",
   "metadata": {},
   "source": [
    "**Bad Prompt**  \n",
    "\"Explain linear regression.\"\n",
    "\n",
    "**Good Prompt**   \n",
    "\"Can you explain the basic concept of linear regression, including its key assumptions and a simple example, for a beginner in statistics?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04819fea-94ca-4d37-af59-6005c40551f8",
   "metadata": {},
   "source": [
    "**Bad Prompt Example**   \n",
    "\"Make a linear regression model.\"  \n",
    "\n",
    "&emsp; *Why it's Bad:*\n",
    "* Lacks Detail: The prompt is too vague and does not specify any parameters or details about the data, the target variable, or the features.\n",
    "* No Context: It doesn’t provide any context about the data or the problem the model is supposed to solve.  \n",
    "* Ambiguous Outcome: It doesn't specify what is expected as an output (e.g., just the model, performance metrics, or predictions).  \n",
    "\n",
    "\n",
    "**Good Prompt Example**  \n",
    "\"Create a linear regression model using the provided dataset named as 'housePrice' to predict housing prices. The dataset includes features such as square footage, number of bedrooms, and age of the house. Use 'price' as the target variable. After creating the model, evaluate its performance using R-squared and Mean Absolute Error (MAE) metrics. Provide a summary of the model's coefficients and predictions for a sample of test data.\"\n",
    "\n",
    "&emsp; *Why it's Good:*\n",
    "* Specific Details: Clearly specifies the target variable ('price') and the features (square footage, number of bedrooms, age).\n",
    "* Context Provided: Gives context about the data (housing prices) and the goal of the model (prediction).\n",
    "* Expected Outcome: Outlines what is expected (model creation, performance evaluation, summary of coefficients, and sample predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a04226c-d8ed-4963-8319-cc8f37cdb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lr_prompt = \"Make a linear regression model.\"                \n",
    "good_lr_prompt = \"\"\"Create a linear regression model using the provided dataset named as 'housePrice' to predict housing prices. \n",
    "    The dataset includes features such as square footage, number of bedrooms, and age of the house. \n",
    "    Use 'price' as the target variable. \n",
    "    After creating the model, evaluate its performance using R-squared and Mean Absolute Error (MAE) metrics. \n",
    "    Provide a summary of the model's coefficients and predictions for a sample of test data.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44adf898-c1e2-444d-b076-ee2b1a92bfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> I can't make a linear regression model without data! To create a model, I need information about the variables you want to explore. \n",
       "> \n",
       "> **Here's what I need from you:**\n",
       "> \n",
       "> 1. **Dataset:** A table of data with at least two columns. \n",
       ">    * One column should represent the **independent variable (X)**. This is the variable you believe might influence or predict the other variable.\n",
       ">    * The other column (or columns) should represent the **dependent variable (Y)**. This is the variable you want to predict or understand.\n",
       "> \n",
       "> 2. **Context:** Tell me about your data. \n",
       ">    * What do the variables represent? (e.g., age, income, temperature, etc.)\n",
       ">    * What are you trying to predict or understand? \n",
       ">    * Are there any specific relationships you expect to see?\n",
       "> \n",
       "> **Once you provide this information, I can:**\n",
       "> \n",
       "> * **Build a linear regression model:** I can find the line of best fit through your data, represented by an equation in the form of `Y = mX + b`.\n",
       "> * **Interpret the results:** I can tell you how strong the relationship is between your variables, how well the model fits the data, and what the coefficients (m and b) mean.\n",
       "> * **Make predictions:** You can give me new values for the independent variable, and I can use the model to predict the corresponding values for the dependent variable.\n",
       "> \n",
       "> **Example:**\n",
       "> \n",
       "> Let's say you want to explore the relationship between the number of hours studied and exam scores. \n",
       "> \n",
       "> * **Dataset:** You could provide a table with \"Hours Studied\" as the independent variable and \"Exam Score\" as the dependent variable.\n",
       "> * **Context:** You're trying to understand if studying more hours leads to higher exam scores.\n",
       "> \n",
       "> I can then build a linear regression model to analyze this relationship.\n",
       "> \n",
       "> **Please provide your data and context so I can help you create your linear regression model!** \n",
       "> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_lr_prompt_response = model.generate_content(good_lr_prompt) \n",
    "to_markdown(avg_lr_prompt_response.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01852672-5d7c-4fb4-a725-d81bf28433f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.linear_model import LinearRegression\n",
       "from sklearn.metrics import r2_score, mean_absolute_error\n",
       "\n",
       "# **1. Load and Prepare the Data**\n",
       "\n",
       "# Assuming 'housePrice' is a CSV file, replace 'your_file_path.csv'\n",
       "house_data = pd.read_csv('your_file_path.csv')\n",
       "\n",
       "# **2. Feature Selection and Data Splitting**\n",
       "features = ['square_footage', 'bedrooms', 'age'] \n",
       "X = house_data[features]\n",
       "y = house_data['price']\n",
       "\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
       "\n",
       "# **3. Model Building**\n",
       "model = LinearRegression()\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "# **4. Model Evaluation**\n",
       "predictions = model.predict(X_test)\n",
       "\n",
       "r2 = r2_score(y_test, predictions)\n",
       "mae = mean_absolute_error(y_test, predictions)\n",
       "\n",
       "print(f\"R-squared: {r2:.2f}\")\n",
       "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
       "\n",
       "# **5. Model Coefficients Interpretation**\n",
       "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
       "print(\"\\nModel Coefficients:\\n\", coefficients)\n",
       "\n",
       "# **6. Predictions on Sample Test Data**\n",
       "sample_data = pd.DataFrame({'square_footage': [1500, 2000], \n",
       "                         'bedrooms': [3, 4], \n",
       "                         'age': [10, 25]})\n",
       "\n",
       "sample_predictions = model.predict(sample_data)\n",
       "print(\"\\nPredictions for Sample Data:\\n\", sample_predictions)\n",
       "```\n",
       "> \n",
       "> **Explanation:**\n",
       "> \n",
       "> 1. **Load and Prepare Data:** \n",
       ">    - Replace 'your_file_path.csv' with the actual path to your 'housePrice' dataset.\n",
       ">    - The code assumes your dataset has columns named 'square_footage', 'bedrooms', 'age', and 'price'. Adjust column names if needed.\n",
       "> \n",
       "> 2. **Feature Selection and Data Splitting:**\n",
       ">    - We select the relevant features for prediction and store them in 'X'. \n",
       ">    - The target variable, 'price', is stored in 'y'.\n",
       ">    - We use `train_test_split` to divide the data into training (80%) and testing (20%) sets.\n",
       "> \n",
       "> 3. **Model Building:**\n",
       ">    - A `LinearRegression` model is created and fitted (trained) on the training data.\n",
       "> \n",
       "> 4. **Model Evaluation:**\n",
       ">    - We predict house prices for the test data and calculate the R-squared and Mean Absolute Error (MAE) to assess model performance.\n",
       ">      - **R-squared:** Measures the proportion of variation in the target variable explained by the model (higher is better).\n",
       ">      - **MAE:**  Represents the average absolute difference between predicted and actual prices (lower is better).\n",
       "> \n",
       "> 5. **Model Coefficients Interpretation:**\n",
       ">    - The code displays the coefficients of the linear equation learned by the model. Each coefficient indicates the estimated change in house price for a one-unit change in the corresponding feature, holding other features constant.\n",
       "> \n",
       "> 6. **Predictions on Sample Test Data:**\n",
       ">    - We create a small 'sample_data' DataFrame to demonstrate how to make predictions on new data using the trained model.\n",
       "> \n",
       "> **Output:**\n",
       "> \n",
       "> - The output will show you the R-squared, MAE, the model's coefficients, and the predicted prices for the sample data.\n",
       "> \n",
       "> **Key Points:**\n",
       "> \n",
       "> - This code provides a basic framework. You might need to handle missing values, explore feature engineering, or try different regression models to improve accuracy depending on your dataset. \n",
       "> - Visualizations (e.g., scatter plots, residual plots) are also helpful for understanding model performance and identifying patterns in your data. \n",
       "> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_lr_prompt_response = model.generate_content(good_lr_prompt) \n",
    "to_markdown(good_lr_prompt_response.text)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a52275-0d4b-469e-b7db-bb099b86abe9",
   "metadata": {},
   "source": [
    "## Build Effective Prompts for Tree-Based Models \n",
    "\n",
    "Tree-Based Models: Includes decision trees, random forests, and gradient boosting machines. \n",
    "\n",
    "**Bad Prompt Example**   \n",
    "\"Create a tree-based model\"\n",
    "\n",
    "**Good Prompt Example**   \n",
    "\"Create a Random Forest classifier using the provided dataset to predict customer churn. The dataset includes features such as customer tenure, monthly charges, and contract type. Use 'churn' as the target variable. After creating the model, evaluate its performance using accuracy, precision, recall, and F1-score metrics. Additionally, provide the feature importance rankings and visualize the first decision tree in the forest.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aaeeeff-5175-4354-9434-5466b5403bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Create a tree-based model.\"              \n",
    "prompt2 = \"\"\"Create a Random Forest classifier using the provided dataset named telecom_churn to predict customer churn. \n",
    "    The dataset has the following features: customer_tenure, monthly_charges, and contract_type.\n",
    "    Split the data in Train - Test proportion of 70:30\n",
    "    Use K-Fold Cross-Validation factor of 10 while building the model and AUC as model performance measure for cross-validation.\n",
    "    Use 'churn' as the target variable. \n",
    "    After creating the model, evaluate its performance using accuracy, precision, recall, and F1-score metrics. \n",
    "    Additionally, provide the feature importance rankings and visualize the first decision tree in the forest.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "922a0cbc-2af1-409a-b1ea-0439aa2d7c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from sklearn.datasets import load_iris\n",
       "from sklearn.tree import DecisionTreeClassifier\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.metrics import accuracy_score\n",
       "\n",
       "# Load the iris dataset\n",
       "iris = load_iris()\n",
       "X = iris.data\n",
       "y = iris.target\n",
       "\n",
       "# Split the data into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Create a decision tree classifier\n",
       "model = DecisionTreeClassifier()\n",
       "\n",
       "# Train the model on the training data\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "# Make predictions on the testing data\n",
       "y_pred = model.predict(X_test)\n",
       "\n",
       "# Evaluate the model\n",
       "accuracy = accuracy_score(y_test, y_pred)\n",
       "print(f\"Accuracy: {accuracy}\")\n",
       "```\n",
       "> \n",
       "> **Explanation:**\n",
       "> \n",
       "> 1. **Import necessary libraries:**\n",
       ">    - `load_iris`: Loads the iris dataset.\n",
       ">    - `DecisionTreeClassifier`: Imports the Decision Tree classifier.\n",
       ">    - `train_test_split`: Splits data into training and testing sets.\n",
       ">    - `accuracy_score`: Calculates the accuracy of the model.\n",
       "> \n",
       "> 2. **Load and prepare data:**\n",
       ">    - `load_iris()`: Loads the iris dataset.\n",
       ">    - `X = iris.data`: Assigns features to `X`.\n",
       ">    - `y = iris.target`: Assigns target variable to `y`.\n",
       ">    - `train_test_split(X, y, test_size=0.2, random_state=42)`: Splits data into 80% training and 20% testing sets with a fixed random state for reproducibility.\n",
       "> \n",
       "> 3. **Create and train the model:**\n",
       ">    - `model = DecisionTreeClassifier()`: Creates a Decision Tree classifier object.\n",
       ">    - `model.fit(X_train, y_train)`: Trains the model using the training features and labels.\n",
       "> \n",
       "> 4. **Make predictions:**\n",
       ">    - `y_pred = model.predict(X_test)`: Predicts the target variable for the test features.\n",
       "> \n",
       "> 5. **Evaluate the model:**\n",
       ">    - `accuracy = accuracy_score(y_test, y_pred)`: Calculates the accuracy of the model by comparing predicted and actual labels.\n",
       ">    - `print(f\"Accuracy: {accuracy}\")`: Prints the accuracy score.\n",
       "> \n",
       "> This code demonstrates a simple implementation of a Decision Tree model for classification. You can modify the code by adjusting parameters like `criterion`, `max_depth`, and others to tune the model's performance. \n",
       "> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBasedModel_Response = model.generate_content(prompt1) \n",
    "to_markdown(treeBasedModel_Response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41366e99-6e24-4687-a60a-04639860a7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split, cross_val_score\n",
       "from sklearn.ensemble import RandomForestClassifier\n",
       "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
       "from sklearn.model_selection import KFold\n",
       "import matplotlib.pyplot as plt\n",
       "from sklearn.tree import plot_tree\n",
       "\n",
       "# **1. Load and Prepare the Data**\n",
       "\n",
       "# Assuming 'telecom_churn.csv' is your dataset file\n",
       "data = pd.read_csv('telecom_churn.csv') \n",
       "\n",
       "# **2. Data Preprocessing**\n",
       "\n",
       "# One-hot encode categorical features (if any)\n",
       "data = pd.get_dummies(data, columns=['contract_type'], drop_first=True)\n",
       "\n",
       "# **3. Split Data into Features and Target**\n",
       "X = data.drop('churn', axis=1)\n",
       "y = data['churn']\n",
       "\n",
       "# **4. Split Data into Training and Testing Sets**\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
       "\n",
       "# **5. Create a Random Forest Classifier**\n",
       "rf_classifier = RandomForestClassifier(random_state=42)\n",
       "\n",
       "# **6. K-Fold Cross-Validation**\n",
       "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
       "auc_scores = cross_val_score(rf_classifier, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
       "\n",
       "print(\"Cross-Validation AUC Scores:\", auc_scores)\n",
       "print(\"Mean AUC Score:\", auc_scores.mean())\n",
       "\n",
       "# **7. Train the Model**\n",
       "rf_classifier.fit(X_train, y_train)\n",
       "\n",
       "# **8. Make Predictions**\n",
       "y_pred = rf_classifier.predict(X_test)\n",
       "\n",
       "# **9. Evaluate the Model**\n",
       "accuracy = accuracy_score(y_test, y_pred)\n",
       "precision = precision_score(y_test, y_pred)\n",
       "recall = recall_score(y_test, y_pred)\n",
       "f1 = f1_score(y_test, y_pred)\n",
       "\n",
       "print(\"\\nModel Evaluation Metrics:\")\n",
       "print(\"Accuracy:\", accuracy)\n",
       "print(\"Precision:\", precision)\n",
       "print(\"Recall:\", recall)\n",
       "print(\"F1-Score:\", f1)\n",
       "\n",
       "# **10. Feature Importance**\n",
       "importances = rf_classifier.feature_importances_\n",
       "feature_names = X.columns\n",
       "\n",
       "# Create a DataFrame for feature importance\n",
       "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
       "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
       "\n",
       "print(\"\\nFeature Importance Rankings:\")\n",
       "print(feature_importance_df)\n",
       "\n",
       "# **11. Visualize the First Decision Tree (Optional)**\n",
       "plt.figure(figsize=(20, 10))\n",
       "plot_tree(rf_classifier.estimators_[0], feature_names=feature_names, filled=True, rounded=True)\n",
       "plt.show()\n",
       "\n",
       "```\n",
       "> \n",
       "> **Explanation:**\n",
       "> \n",
       "> 1. **Load and Prepare Data:** Load your 'telecom_churn.csv' dataset.\n",
       "> 2. **Data Preprocessing:** Handle categorical features using one-hot encoding.\n",
       "> 3. **Split Data:** Split into features (X) and the target variable (y), then into training and testing sets.\n",
       "> 4. **Create Classifier:** Initialize a RandomForestClassifier.\n",
       "> 5. **K-Fold Cross-Validation:** Perform 10-fold cross-validation using AUC as the evaluation metric.\n",
       "> 6. **Train Model:** Train the Random Forest model on the training data.\n",
       "> 7. **Make Predictions:** Use the trained model to predict churn on the test data.\n",
       "> 8. **Evaluate Model:** Calculate accuracy, precision, recall, and F1-score.\n",
       "> 9. **Feature Importance:** Get feature importance scores and display them.\n",
       "> 10. **Visualize Decision Tree (Optional):** Visualize the first decision tree in the forest (can be computationally expensive for large forests).\n",
       "> \n",
       "> **Remember to replace 'telecom_churn.csv' with the actual file name of your dataset.** \n",
       "> "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBasedModel_Response = model.generate_content(prompt2) \n",
    "to_markdown(treeBasedModel_Response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43f857fb-0743-428c-93d2-8564a8e45cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a Random Forest classifier using the provided dataset to predict customer churn. The name of the dataset is df. The dataset includes features such as customer tenure, monthly charges, contract type. Use 'churn' as the target variable. After creating the model, evaluate its performance using accuracy, precision, recall, F1-score metrics. Additionally, provide the feature importance rankings and visualize the first decision tree in the forest.\n"
     ]
    }
   ],
   "source": [
    "def generate_modeling_prompt(model_type, task, dataset_description, features, target_variable, metrics, additional_requirements):\n",
    "    prompt = (\n",
    "        f\"Create a {model_type} using the provided dataset to {task}. \"\n",
    "        f\"{dataset_description}. \"\n",
    "        f\"The dataset includes features such as {', '.join(features)}. \"\n",
    "        f\"Use '{target_variable}' as the target variable. \"\n",
    "        f\"After creating the model, evaluate its performance using {', '.join(metrics)} metrics. \"\n",
    "        f\"{additional_requirements}\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# Example usage\n",
    "model_type = \"Random Forest classifier\"\n",
    "task = \"predict customer churn\"\n",
    "dataset_description = \"The name of the dataset is df\"\n",
    "features = [\"customer tenure\", \"monthly charges\", \"contract type\"]\n",
    "target_variable = \"churn\"\n",
    "metrics = [\"accuracy\", \"precision\", \"recall\", \"F1-score\"]\n",
    "additional_requirements = (\n",
    "    \"Additionally, provide the feature importance rankings and visualize the first decision tree in the forest.\"\n",
    ")\n",
    "\n",
    "TreeBasedPrompt = generate_modeling_prompt(model_type, task, dataset_description, features, target_variable, metrics, additional_requirements)\n",
    "print(TreeBasedPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84061ade-bf2b-4b1b-bd14-56b5ea9fb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TBM_response = model.generate_content(TreeBasedPrompt)\n",
    "to_markdown(TBM_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfa7ab-8a37-4ed3-b467-7e3499296e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad776fd5-c8a2-479f-99be-84637879aef2",
   "metadata": {},
   "source": [
    "# Use Generative AI to describe Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df0c1a-b5d6-47ac-b186-2e30330710a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37341d-0ea3-414e-8a20-c3d9f051efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o image.jpg https://t0.gstatic.com/licensed-image?q=tbn:ANd9GcQ_Kevbk21QBRy-PgB4kQpS79brbmmEG7m3VOTShAn4PecDU5H5UxrJxE3Dw1JiaG17V88QIol19-3TM2wCHw\n",
    "img1 = PIL.Image.open('image.jpg')\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316ae7d-f945-4790-bcfa-8eae4371ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img1)\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303d9fb-0ef9-4840-b846-58c34310b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o image.jpg https://images.pexels.com/photos/414612/pexels-photo-414612.jpeg\n",
    "img2 = PIL.Image.open('image.jpg')\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9223e06-c1de-4261-bac3-316b45654f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img2)\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6d4f2-d418-4a78-8e76-d64455e422cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o image.jpg https://cdn.pixabay.com/photo/2015/04/23/22/00/tree-736885_960_720.jpg\n",
    "img3 = PIL.Image.open('image.jpg')\n",
    "img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698909b-7bac-4916-804c-e26021feeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img3)\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e2730-d4d2-46d0-b4e2-2b4b4320c08f",
   "metadata": {},
   "source": [
    "### Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39534176-f518-4cd4-9593-8154973300cc",
   "metadata": {},
   "source": [
    "##### If you are using LangChain with OpenAI. You may require the following installations\n",
    "- pip install langchain\n",
    "- pip install openai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
